{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"데이터셋.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"LrI6lOUSQ1Sy"},"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","import os\n","import numpy as np\n","import json\n","\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import matplotlib.image as img\n","\n","import cv2\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7diNVRUES_7O"},"source":["#기본적으로 label에 해당하는 json파일에 정보가 image양 보다 많다.\n","#가령 (label File)20201028_cat-arch-000156.mp4.json 파일 안에는 frame_0, frame_3, frame_6,...,frame 258까지 있는데 반해, \n","#(Image file)20201028_cat-arch-000156.mp4안의 image는 25개 정도 밖에 없다...\n","#심지어 json파일내 frame 숫자가 일정한 숫자 간격으로 늘어나는 것도 아니다. 예) frame_0, frame_3 다음 frame숫자는? frame_6이라 단정못함. frame_9일 수 도 있음...\n","#자세한 정보는 파일 한번 열어보시면, 알 수 있습니다. 로컬 컴퓨터에 데이터 작은거 몇개 열어보시면 보기 더 편하실 듯 합니다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1EqIH7WeQ46Z"},"source":["#Label파일과 image파일에 약간의? 문제가 있는 관계로 고민을 좀 많이했다.\n","#그 결과, dataset class getitem에서 image랑 그 image에 맞는 필요한 부분만 뽑아서 사용하려 한다. \n","\n","class cnn_dataset(Dataset):\n","  def __init__(self, label_dir, image_dir, transform=None):\n","    self.label_dir = label_dir\n","    self.image_dir = image_dir\n","    self.transform = transform\n","\n","    list_image = os.listdir(self.image_dir)\n","    self.list_image = list_image\n","\n","  #이미지 하나 당 target 생성\n","  def __getitem__(self, index):\n","    image = os.path.join(self.image_dir, self.list_image[index])\n","    image = Image.open(image).convert('RGB')\n","    #image = np.asarray(image)\n","\n","    target = Make_target(self.label_dir, Find_frame_num(self.list_image[index])) #밑에 Make_target함수와 Find_frame_num함수 설명이 있습니다.\n","    \n","    if self.transform:\n","      image = self.transform(image)\n","\n","    target = torch.tensor(target)\n","\n","    data = {'image':image, 'target':target}\n","    return data\n","\n","  def __len__(self):\n","    return len(self.list_image)\n","       "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jXhcYdZdQ-LR"},"source":["#yolo용 target 구조: (x, y, w, h, c, cat, dog, i, j)\n","#만약 CNN 학습을 위해 target에 breed를 추가하신다면, (breed, x, y, w, h, c, cat, dog, i, j)\n","\n","#Image에 필요한 target을 만들려고함\n","#근데 존나 마음아픈게 frame별로 걍 마구잡이로 되 있어서, Image파일 이름에 있는 frame 숫자를 이용해서 멥핑. /ARCH/20201028_cat-arch-000156.mp4/frame_102_timestamp_0.jpg => 102  \n","#이 함수는 라벨(json)과 frame_num을 인자로 받아 해당 frame에 대한 bounding box, speices, responsible grid cell을 찾는다. *추가: 만약 breed가 추가된다면 breed도...\n","def Make_target(label_dir, frame_num):\n","  with open(label_dir) as f:\n","    label_json = json.load(f)\n","  \n","  s = 8\n","\n","  target_list = []\n","  #바운딩박스 찾기\n","  target_list.append(label_json['metadata']['breed'])\n","  for i in range(len(label_json['annotations'])):\n","    if label_json['annotations'][i]['frame_number'] == frame_num:\n","       target_list.append(label_json['annotations'][i]['bounding_box']['x'])\n","       target_list.append(label_json['annotations'][i]['bounding_box']['y'])\n","       target_list.append(label_json['annotations'][i]['bounding_box']['width'])\n","       target_list.append(label_json['annotations'][i]['bounding_box']['height'])\n","  \n","  #바운딩박스 yolo의 target 형식에 맞게 변경\n","  image_width = label_json['metadata']['width']\n","  image_height = label_json['metadata']['height']\n","\n","  s_image_width = image_width / 8\n","  s_image_height = image_height / 8\n","\n","  i, j = 0, 0\n","  while(i*s_image_width < target_list[0]):\n","    i += 1\n","\n","  while(j*s_image_height < target_list[1]):\n","    j += 1\n","\n","  i -= 1\n","  j -= 1\n","  \n","  target_list[0] = target_list[0]/s_image_width - i\n","  target_list[1] = target_list[1]/s_image_height - j\n","  target_list[2] /= s_image_width\n","  target_list[3] /= s_image_height\n","\n","\n","  #confidence score를 1로 설정\n","  target_list.append(1.0)\n","\n","  #고양이면 1, 0 을 강아지면 0,1을 append\n","  if label_json['metadata']['species'] == 'CAT':\n","    target_list.append(1.0)\n","    target_list.append(0)\n","  else:\n","    target_list.append(0)\n","    target_list.append(1.0)\n","\n","  target_list.append(i)\n","  target_list.append(j)\n","  \n","  return target_list  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PQ_nzA7RAjX"},"source":["#이미지 파일 이름을 이용해서, frame 숫자를 뽑아내는 함수이다.\n","def Find_frame_num(image_filename):\n","  frame_num = ''\n","  count_ = 0\n","  \n","\n","  for i in range(len(image_filename)):\n","    if image_filename[i] == '_':\n","      count_ += 1\n","      if count_ == 2:\n","        break\n","      continue\n","    if count_ == 1:\n","      frame_num += image_filename[i]\n","  \n","  frame_num = int(frame_num)\n","  return frame_num\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jlk696dxRF7z"},"source":[""],"execution_count":null,"outputs":[]}]}