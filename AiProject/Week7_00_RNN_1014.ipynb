{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Week7_00_RNN_1014.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"be1a2969bf954df4bcd582eaf9985dd6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_653f41dcb43c467ba4ef49b509329293","IPY_MODEL_8a6a2c163ddb4424b15cb109b18e5e53","IPY_MODEL_62288a959ebe4fc694c2d224ec398e1d"],"layout":"IPY_MODEL_a4a7c3bb37c94f78878f62e75cce19f5"}},"653f41dcb43c467ba4ef49b509329293":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a6d651663404080bb3a4007cb46c762","placeholder":"​","style":"IPY_MODEL_5aee1709a64e4d78971ab72bad1395de","value":""}},"8a6a2c163ddb4424b15cb109b18e5e53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14ebc93f2a764c0a8966b9309d2fdf56","max":9912422,"min":0,"orientation":"horizontal","style":"IPY_MODEL_538809b7502f4b308255302740c6aa78","value":9912422}},"62288a959ebe4fc694c2d224ec398e1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7986bd8bcacb4aaaaffb0993ba343ab8","placeholder":"​","style":"IPY_MODEL_545f77055c22498e822e838807909997","value":" 9913344/? [00:00&lt;00:00, 34844863.66it/s]"}},"a4a7c3bb37c94f78878f62e75cce19f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a6d651663404080bb3a4007cb46c762":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aee1709a64e4d78971ab72bad1395de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14ebc93f2a764c0a8966b9309d2fdf56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"538809b7502f4b308255302740c6aa78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7986bd8bcacb4aaaaffb0993ba343ab8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"545f77055c22498e822e838807909997":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"93lS-AmcovBt"},"source":["# 1. RNN"]},{"cell_type":"markdown","metadata":{"id":"2Qbo7PtNCsN1"},"source":["To understand RNN, one should know some data are sequential  \n","Sequential data is literally data in sequence, that is, the order of matters\n","\n","For non-sequential data types, e.g. sets, the below would be true\n","```python\n","{1, 2, 3} == {1, 3, 2}\n","```\n","But for sequential data:\n","```python\n","[1, 2, 3] != [1, 3, 2]\n","```\n","__Time series__ is a type of sequential data, which data points are recorded successively over a time period"]},{"cell_type":"markdown","metadata":{"id":"w-ZkRU1FIg3m"},"source":["## RNN Basics"]},{"cell_type":"code","metadata":{"id":"-zAXWDPjGbSH"},"source":["import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fJ9fX49AGePa","executionInfo":{"elapsed":43,"status":"ok","timestamp":1634203083902,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"},"user_tz":-540},"outputId":"1a63df77-6676-482e-d055-1c5f3a2a8ed2"},"source":["seq = torch.arange(1., 16.)\n","\n","print(type(seq))\n","print(seq)\n","print(seq.size())"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'torch.Tensor'>\n","tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n","        15.])\n","torch.Size([15])\n"]}]},{"cell_type":"code","metadata":{"id":"eefgQktAGz2O"},"source":["# Number of previous data points to be taken in account\n","seq_length = 5\n","batch_size = len(seq) // seq_length\n","# Number of features\n","input_size = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l3sJbZxoHrRG","executionInfo":{"elapsed":39,"status":"ok","timestamp":1634203083905,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"},"user_tz":-540},"outputId":"4f94a2de-ad93-4927-9802-26a08cfe0751"},"source":["X = seq.view(batch_size, seq_length, input_size)\n","\n","print(X.size())"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 5, 1])\n"]}]},{"cell_type":"code","metadata":{"id":"7FQzDaXGAv56"},"source":["import torch.nn as nn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Vz1nvkj26Ds"},"source":["# Number of features in hidden state\n","hidden_size = 10\n","# Number of RNN layers stacked\n","num_layers = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Amn5lfCp26FN"},"source":["singleRNN = nn.RNN(\n","    input_size=input_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    nonlinearity='tanh',\n","    batch_first=True,\n","    dropout=0,\n","    bidirectional=False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kKER6Nvu26Ft","executionInfo":{"elapsed":28,"status":"ok","timestamp":1634203083908,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"},"user_tz":-540},"outputId":"c88a4a68-0e29-414f-feb3-40ed044f282e"},"source":["y, h = singleRNN(X)\n","\n","print(y.size())    # (batch_size, seq_length, hidden_size * num_directions)\n","print(h.size())    # (num_layers * num_directions, batch_size, hidden_size)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 5, 10])\n","torch.Size([1, 3, 10])\n"]}]},{"cell_type":"markdown","metadata":{"id":"iF3--inA26Hi"},"source":["## Image Classification with RNN"]},{"cell_type":"code","metadata":{"id":"A0soapA-26Hj"},"source":["import torchvision\n","import torchvision.transforms as transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471,"referenced_widgets":["be1a2969bf954df4bcd582eaf9985dd6","653f41dcb43c467ba4ef49b509329293","8a6a2c163ddb4424b15cb109b18e5e53","62288a959ebe4fc694c2d224ec398e1d","a4a7c3bb37c94f78878f62e75cce19f5","5a6d651663404080bb3a4007cb46c762","5aee1709a64e4d78971ab72bad1395de","14ebc93f2a764c0a8966b9309d2fdf56","538809b7502f4b308255302740c6aa78","7986bd8bcacb4aaaaffb0993ba343ab8","545f77055c22498e822e838807909997","673c6d76abc94edc93a537e3a5179200","a50676951f89473082bfa6caf5e5c626","e3ea5002b47e4b3aa6833a3fa7d74b06"]},"id":"n0QHbjiO26Hm","executionInfo":{"elapsed":1599,"status":"ok","timestamp":1634203215332,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"},"user_tz":-540},"outputId":"f6fb2e82-adfc-4a50-9e3c-e5e24f8e3a09"},"source":["transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","trainset = torchvision.datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n","testset = torchvision.datasets.MNIST(root='./mnist', train=False, transform=transform)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be1a2969bf954df4bcd582eaf9985dd6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/9912422 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"673c6d76abc94edc93a537e3a5179200","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/28881 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a50676951f89473082bfa6caf5e5c626","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1648877 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3ea5002b47e4b3aa6833a3fa7d74b06","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4542 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"]}]},{"cell_type":"code","metadata":{"id":"X3kTyice26Ht"},"source":["batch_size = 1000\n","num_workers = 0\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kgDPOcWl26Hy"},"source":["class ImageRNN(nn.Module):\n","    def __init__(self, batch_size, seq_length, input_size, hidden_size, num_layers, num_classes):\n","        super().__init__()\n","        self.batch_size = batch_size\n","        self.seq_length = seq_length\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.num_classes = num_classes\n","        \n","        self.rnn = nn.RNN(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n","        self.fc = nn.Linear(self.hidden_size * self.seq_length, self.num_classes)\n","\n","    def forward(self, x, h0):\n","        x = x.view(-1, 28, 28)    # (batch_size, channel, width, height) --> (batch_size, width as seq_length, height * channel as feature)\n","        out, _ = self.rnn(x, h0)    # (batch_size, seq_length, num_directions * hidden_size)\n","        out = out.reshape(-1, (self.seq_length * self.hidden_size))    # (batch, seq_length * num_directions * hidden_size)\n","        outputs = self.fc(out)    # (batch_size, num_classes)\n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zE_rI6qP26H-"},"source":["import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pWtbv9G626H1"},"source":["seq_length = 28\n","input_size = 28\n","hidden_size = 50\n","num_layers = 1\n","num_classes = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q4LfTgXz26H6"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"96S9txVi26IB"},"source":["model = ImageRNN(batch_size, seq_length, input_size, hidden_size, num_layers, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"NDSAGZYc26IE","outputId":"8873749d-adef-42aa-8644-3bf1193574eb"},"source":["epochs = 10\n","\n","model.train()\n","for epoch in range(epochs):\n","    train_loss = 0\n","    train_correct = 0\n","\n","    for x, y in trainloader:\n","        x, y = x.to(device), y.to(device)\n","        h0 = torch.zeros(num_layers, batch_size, hidden_size).to(device)    # (num_layers * num_directions, batch_size, hidden_size)\n","\n","        optimizer.zero_grad()\n","        outputs = model(x, h0)\n","        loss = criterion(outputs, y)\n","                \n","        loss.backward()\n","        optimizer.step()\n","        \n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        train_correct += predicted.eq(y).sum().item()\n","        \n","    train_loss = train_loss / len(trainloader)\n","    train_acc = train_correct / len(trainset)\n","        \n","    print('[%2d] TRAIN loss: %.4f, acc: %.4f' % (epoch + 1, train_loss, train_acc))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[ 1] TRAIN loss: 0.9553, acc: 0.7494\n","[ 2] TRAIN loss: 0.3527, acc: 0.8954\n","[ 3] TRAIN loss: 0.2872, acc: 0.9145\n","[ 4] TRAIN loss: 0.2453, acc: 0.9264\n","[ 5] TRAIN loss: 0.2103, acc: 0.9372\n","[ 6] TRAIN loss: 0.1858, acc: 0.9450\n","[ 7] TRAIN loss: 0.1644, acc: 0.9512\n","[ 8] TRAIN loss: 0.1482, acc: 0.9549\n","[ 9] TRAIN loss: 0.1345, acc: 0.9594\n","[10] TRAIN loss: 0.1241, acc: 0.9626\n"]}]},{"cell_type":"code","metadata":{"id":"KGKQPHat26II"},"source":["test_loss = 0\n","test_correct = 0\n","test_preds = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for x, y in testloader:\n","        x, y = x.to(device), y.to(device)\n","        h0 = torch.zeros(num_layers, batch_size, hidden_size).to(device)\n","\n","        outputs = model(x, h0)\n","        loss = criterion(outputs, y)\n","        \n","        test_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        test_correct += predicted.eq(y).sum().item()\n","        \n","        test_preds.extend(predicted.tolist())\n","        \n","print('TEST loss: %.4f, acc: %.4f' % (test_loss/len(testloader), test_correct/len(testset)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NQIKPhYh26F_"},"source":["## Stacked RNN"]},{"cell_type":"code","metadata":{"id":"ayOei0N8ktrl","executionInfo":{"status":"ok","timestamp":1634207330702,"user_tz":-540,"elapsed":374,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}}},"source":["batch_size = 3\n","input_size = 1\n","seq_length = 5\n","hidden_size = 10\n","num_layers = 4"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"BvQkg6jH26GA","executionInfo":{"status":"ok","timestamp":1634207333539,"user_tz":-540,"elapsed":242,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}}},"source":["stackedRNN = nn.RNN(\n","    input_size=input_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    batch_first=True\n",")"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZT6MshC26GF","executionInfo":{"status":"ok","timestamp":1634207334932,"user_tz":-540,"elapsed":257,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}}},"source":["X = seq.view(batch_size, seq_length, input_size)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqeuc6JX26GL","executionInfo":{"status":"ok","timestamp":1634207336354,"user_tz":-540,"elapsed":247,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}}},"source":["y, h_n = stackedRNN(X)"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"ehdd-Afm26GQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634207363716,"user_tz":-540,"elapsed":231,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}},"outputId":"85cc9bc0-5b74-4879-9edd-3144088d1bec"},"source":["h_n"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.9048,  0.4621,  0.7174,  0.2272, -0.9388, -0.6431, -0.1270,\n","           0.9585,  0.5300, -0.2213],\n","         [ 0.9959,  0.7727,  0.8971, -0.0380, -0.9931, -0.7666, -0.1566,\n","           0.9979,  0.8297, -0.0442],\n","         [ 0.9998,  0.8888,  0.9725, -0.3779, -0.9994, -0.8582, -0.0568,\n","           0.9999,  0.9311,  0.1846]],\n","\n","        [[ 0.3434,  0.4689,  0.5425, -0.0331,  0.6038, -0.4746, -0.6549,\n","           0.2860,  0.4269,  0.4532],\n","         [ 0.3601,  0.5062,  0.6590, -0.0535,  0.5990, -0.5041, -0.6330,\n","           0.4261,  0.3173,  0.4469],\n","         [ 0.2185,  0.5265,  0.7494, -0.1057,  0.6154, -0.4421, -0.5494,\n","           0.4028,  0.2020,  0.3811]],\n","\n","        [[ 0.3932, -0.2890, -0.4712,  0.3995,  0.4612, -0.0808,  0.6431,\n","           0.5708,  0.1292, -0.6724],\n","         [ 0.3877, -0.3565, -0.4649,  0.4352,  0.4804, -0.1517,  0.6827,\n","           0.5851,  0.0891, -0.6681],\n","         [ 0.3351, -0.3333, -0.4447,  0.4969,  0.4958, -0.1819,  0.6879,\n","           0.5927,  0.1076, -0.6775]],\n","\n","        [[ 0.7001,  0.0787,  0.2652,  0.2283,  0.5672,  0.2347,  0.1115,\n","          -0.2318, -0.4532,  0.3268],\n","         [ 0.7202,  0.1021,  0.2566,  0.2015,  0.5819,  0.2430,  0.0912,\n","          -0.2573, -0.4543,  0.3504],\n","         [ 0.7075,  0.1083,  0.2582,  0.1853,  0.6066,  0.2524,  0.0849,\n","          -0.2267, -0.4256,  0.3603]]], grad_fn=<StackBackward>)"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"okFOis2X26Gb"},"source":["## Bi-directional RNN"]},{"cell_type":"code","metadata":{"id":"oetb606626Gc","executionInfo":{"status":"ok","timestamp":1634205108731,"user_tz":-540,"elapsed":245,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}}},"source":["biRNN = nn.RNN(\n","    input_size=input_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    batch_first=True,\n","    bidirectional=True\n",")"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"wkwe0y4vU7tH","executionInfo":{"status":"ok","timestamp":1634205110482,"user_tz":-540,"elapsed":8,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}}},"source":["y, h_n = biRNN(X)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"4g3hYAsU26Gu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634205111907,"user_tz":-540,"elapsed":364,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}},"outputId":"01413443-5ca7-427b-8610-24079cb52eaf"},"source":["print(y.size())    # (batch_size, seq_length, hidden_size * num_directions)\n","print(h_n.size())    # (num_layers * num_directions, batch_size, hidden_size)"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 5, 20])\n","torch.Size([8, 3, 10])\n"]}]},{"cell_type":"code","metadata":{"id":"76NejugL26G3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634205113710,"user_tz":-540,"elapsed":353,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}},"outputId":"c54bee47-3192-4f13-cc44-fff4520c4cd2"},"source":["y_bi = y.view(batch_size, seq_length, 2, hidden_size)\n","\n","print(y_bi.size())"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 5, 2, 10])\n"]}]},{"cell_type":"code","metadata":{"id":"TGxdE5LD26HB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634205116096,"user_tz":-540,"elapsed":5,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}},"outputId":"4ca9bbbc-686c-49c4-a5f0-b54a8a36a61c"},"source":["y_forward = y_bi[:,:,0,:]\n","y_backward = y_bi[:,:,1,:]\n","\n","print(y_forward.size())\n","print(y_backward.size())"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 5, 10])\n","torch.Size([3, 5, 10])\n"]}]},{"cell_type":"code","metadata":{"id":"I2uH75ha26HM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634205117816,"user_tz":-540,"elapsed":243,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}},"outputId":"794aa702-cbd5-4136-ac23-2924fb887796"},"source":["h_n_bi = h_n.view(num_layers, 2, batch_size, hidden_size)\n","\n","print(h_n_bi.size())"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 2, 3, 10])\n"]}]},{"cell_type":"code","metadata":{"id":"tTrAhJbl26HS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634205119675,"user_tz":-540,"elapsed":4,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}},"outputId":"412b5e99-0aef-4fb1-cfa4-85aead72fc74"},"source":["h_n_forward = h_n_bi[:,:,0,:]\n","h_n_backward = h_n_bi[:,:,1,:]\n","\n","print(h_n_forward.size())\n","print(h_n_backward.size())"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 2, 10])\n","torch.Size([4, 2, 10])\n"]}]},{"cell_type":"markdown","metadata":{"id":"TRgaV-co4AW3"},"source":["## LSTM\n"]},{"cell_type":"code","metadata":{"id":"RC8TVAa527x-","executionInfo":{"status":"ok","timestamp":1634205121635,"user_tz":-540,"elapsed":362,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}}},"source":["lstm = nn.LSTM(\n","    input_size=input_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    batch_first=True,\n","    dropout=0,\n","    bidirectional=False\n",")"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"0YXg6KSV27yL","executionInfo":{"status":"ok","timestamp":1634205123297,"user_tz":-540,"elapsed":5,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}}},"source":["y, h_n = lstm(X)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1CE5aQM27yV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634205126191,"user_tz":-540,"elapsed":243,"user":{"displayName":"이동혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07314889758459321342"}},"outputId":"76404f74-bbf0-436a-b4bf-50700f6f4755"},"source":["print(y.size())    # (batch_size, seq_length, hidden_size * num_directions)"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 5, 10])\n"]}]},{"cell_type":"markdown","metadata":{"id":"hZ9j8h6nWuMo"},"source":["## Character Prediction with RNN"]},{"cell_type":"code","metadata":{"id":"30E90kVHWt0K"},"source":["char_set = ['d', 'e', 'h', 'l', 'o', 'r', 'w', ' ']\n","\n","input_size = len(char_set)\n","hidden_size = 16\n","output_size = len(char_set)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Von6_jBdXA9s"},"source":["x = [[2, 1, 3, 3, 4, 7, 6, 4, 5, 3]] # hello worl\n","x_onehot = [[[0, 0, 1, 0, 0, 0, 0, 0],  # h\n","             [0, 1, 0, 0, 0, 0, 0, 0],  # e\n","             [0, 0, 0, 1, 0, 0, 0, 0],  # l\n","             [0, 0, 0, 1, 0, 0, 0, 0],  # l\n","             [0, 0, 0, 0, 1, 0, 0, 0],  # o\n","             [0, 0, 0, 0, 0, 0, 0, 1],  #\n","             [0, 0, 0, 0, 0, 0, 1, 0],  # w\n","             [0, 0, 0, 0, 1, 0, 0, 0],  # o\n","             [0, 0, 0, 0, 0, 1, 0, 0],  # r\n","             [0, 0, 0, 1, 0, 0, 0, 0]]]\n","\n","y = [[1, 3, 3, 4, 7, 6, 4, 5, 3, 0]] # ello world\n","\n","X = torch.FloatTensor(x_onehot)\n","Y = torch.LongTensor(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z5n-HlblZNzs"},"source":["class simpleRNN(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.rnn = torch.nn.RNN(input_dim, hidden_dim, batch_first=True)\n","        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        x, _status = self.rnn(x)\n","        x = self.fc(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2IW6PbyPZVnM"},"source":["model = simpleRNN(input_size, hidden_size, output_size)\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), 0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghTwhXsAbWbn"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GGUyWnOCZcGZ"},"source":["epochs = 5\n","\n","model.train()\n","for epoch in range(epochs):\n","    optimizer.zero_grad()\n","    outputs = model(X)\n","    loss = criterion(outputs.view(-1, input_size), Y.view(-1))\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","    predicted = outputs.data.numpy().argmax(axis=2)\n","    prediction = ''.join([char_set[c] for c in np.squeeze(predicted)])\n","    print('[%2d] TRAIN loss: %.4f, pred: %s' % (epoch + 1, loss.item(), prediction))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zMiOnSndfz5Y"},"source":["## Gender Classficiation with RNN"]},{"cell_type":"code","metadata":{"id":"0pGuELEFf5xN"},"source":["char_set = ['a', 'd', 'e', 'h', 'i', 'n', 'o', 'p', 'r', 's', 'w']\n","input_size = len(char_set)\n","hidden_size = 22\n","output_size = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BV70n2T1f5oG"},"source":["x = [[0, 5, 1, 8, 2, 10], # andrew,\n","     [9, 6, 7, 3, 4, 0]]  # sophia\n","\n","x_onehot = [[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # a\n","             [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],  # n\n","             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # d\n","             [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],  # r\n","             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],  # e\n","             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], # w\n","            \n","            [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],  # s\n","             [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],  # o\n","             [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],  # p\n","             [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],  # h\n","             [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],  # i\n","             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]] # a\n","\n","y = [[0],  # Male\n","     [1]]  # Female\n","\n","X = torch.FloatTensor(x_onehot)\n","Y = torch.FloatTensor(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BL9nF4gPgeON"},"source":["class simpleRNN(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super().__init__()\n","        self.rnn = torch.nn.RNN(input_dim, hidden_dim, batch_first=True)\n","        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        x, _status = self.rnn(x)\n","        x = self.fc(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5NXvTTjzggpD"},"source":["model = simpleRNN(input_size, hidden_size, output_size)\n","criterion = torch.nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), 0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCoiS3tcgkl0"},"source":["epochs = 20\n","\n","for epoch in range(epochs):\n","    optimizer.zero_grad()\n","    outputs = model(X)\n","    loss = criterion(outputs[:, -1, :].squeeze(), Y.view(-1))\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","    predicted = [\"Male\" if x < 0.5 else \"Female\" for x in outputs[:, -1, :].squeeze().tolist()]\n","    print('[%2d] TRAIN loss: %.4f, pred: %s' % (epoch + 1, loss.item(), predicted))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_CHVNr36cFOn"},"source":["## Seq2Seq"]},{"cell_type":"code","metadata":{"id":"jOBCmLOQAIcF"},"source":["raw = [\"I feel hungry.\t나는 배가 고프다.\",\n","       \"Pytorch is very easy.\t파이토치는 매우 쉽다.\",\n","       \"Pytorch is a framework for deep learning.\t파이토치는 딥러닝을 위한 프레임워크이다.\",\n","       \"Pytorch is very clear to use.\t파이토치는 사용하기 매우 직관적이다.\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JuazViVlAIcH"},"source":["# Fix token for \"start of sentence\" and \"end of sentence\"\n","SOS_token = 0\n","EOS_token = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3avydpwOAIcK"},"source":["# Class for vocabulary related information of data\n","class Vocab:\n","    def __init__(self):\n","        self.vocab2index = {\"<SOS>\": SOS_token, \"<EOS>\": EOS_token}\n","        self.index2vocab = {SOS_token: \"<SOS>\", EOS_token: \"<EOS>\"}\n","        self.vocab_count = {}\n","        self.n_vocab = len(self.vocab2index)\n","\n","    def add_vocab(self, sentence):\n","        for word in sentence.split(\" \"):\n","            if word not in self.vocab2index:\n","                self.vocab2index[word] = self.n_vocab\n","                self.vocab_count[word] = 1\n","                self.index2vocab[self.n_vocab] = word\n","                self.n_vocab += 1\n","            else:\n","                self.vocab_count[word] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eb6GpKghAIcL"},"source":["# Filter out the long sentence from source and target data\n","def filter_pair(pair, source_max_length, target_max_length):\n","    return len(pair[0].split(\" \")) < source_max_length and len(pair[1].split(\" \")) < target_max_length"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEP0b077AIcO"},"source":["# Read and preprocess the corpus data\n","def preprocess(corpus, source_max_length, target_max_length):\n","    print(\"...Reading corpus...\")\n","    pairs = []\n","    for line in corpus:\n","        pairs.append([s for s in line.strip().lower().split(\"\\t\")])\n","    print(\"Read {} sentence pairs\".format(len(pairs)))\n","\n","    pairs = [pair for pair in pairs if filter_pair(pair, source_max_length, target_max_length)]\n","    print(\"Trimmed to {} sentence pairs\".format(len(pairs)))\n","\n","    source_vocab = Vocab()\n","    target_vocab = Vocab()\n","\n","    print(\"...Counting words...\")\n","    for pair in pairs:\n","        source_vocab.add_vocab(pair[0])\n","        target_vocab.add_vocab(pair[1])\n","    print(\"source vocab size =\", source_vocab.n_vocab)\n","    print(\"target vocab size =\", target_vocab.n_vocab)\n","\n","    return pairs, source_vocab, target_vocab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lozRyCsuAIcQ"},"source":["class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(Encoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, x, hidden):\n","        x = self.embedding(x).view(1, 1, -1)\n","        x, hidden = self.gru(x, hidden)\n","        return x, hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTgf-C2xAIcS"},"source":["class Decoder(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(Decoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, x, hidden):\n","        x = self.embedding(x).view(1, 1, -1)\n","        x, hidden = self.gru(x, hidden)\n","        x = self.softmax(self.out(x[0]))\n","        return x, hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3YOUpmMiAIcU"},"source":["# Convert sentence to the index tensor\n","def tensorize(vocab, sentence):\n","    indexes = [vocab.vocab2index[word] for word in sentence.split(\" \")]\n","    indexes.append(vocab.vocab2index[\"<EOS>\"])\n","    return torch.Tensor(indexes).long().to(device).view(-1, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_e7APioRAIcW"},"source":["# Training seq2seq\n","def train(pairs, source_vocab, target_vocab, encoder, decoder, n_iter, print_every=1000, learning_rate=0.01):\n","    loss_total = 0\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","\n","    training_batch = [random.choice(pairs) for _ in range(n_iter)]\n","    training_source = [tensorize(source_vocab, pair[0]) for pair in training_batch]\n","    training_target = [tensorize(target_vocab, pair[1]) for pair in training_batch]\n","\n","    criterion = nn.NLLLoss()\n","\n","    for i in range(1, n_iter + 1):\n","        source_tensor = training_source[i - 1]\n","        target_tensor = training_target[i - 1]\n","\n","        encoder_hidden = torch.zeros([1, 1, encoder.hidden_size]).to(device)\n","\n","        encoder_optimizer.zero_grad()\n","        decoder_optimizer.zero_grad()\n","\n","        source_length = source_tensor.size(0)\n","        target_length = target_tensor.size(0)\n","\n","        loss = 0\n","\n","        for enc_input in range(source_length):\n","            _, encoder_hidden = encoder(source_tensor[enc_input], encoder_hidden)\n","\n","        decoder_input = torch.Tensor([[SOS_token]]).long().to(device)\n","        decoder_hidden = encoder_hidden # connect encoder output to decoder input\n","\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # teacher forcing\n","\n","        loss.backward()\n","\n","        encoder_optimizer.step()\n","        decoder_optimizer.step()\n","\n","        loss_iter = loss.item() / target_length\n","        loss_total += loss_iter\n","\n","        if i % print_every == 0:\n","            loss_avg = loss_total / print_every\n","            loss_total = 0\n","            print(\"[{} - {}%] loss = {:05.4f}\".format(i, i / n_iter * 100, loss_avg))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHv2pjjAAIcY"},"source":["# Insert given sentence to check the training\n","def evaluate(pairs, source_vocab, target_vocab, encoder, decoder, target_max_length):\n","    for pair in pairs:\n","        print(\">\", pair[0])\n","        print(\"=\", pair[1])\n","        source_tensor = tensorize(source_vocab, pair[0])\n","        source_length = source_tensor.size()[0]\n","        encoder_hidden = torch.zeros([1, 1, encoder.hidden_size]).to(device)\n","\n","        for ei in range(source_length):\n","            _, encoder_hidden = encoder(source_tensor[ei], encoder_hidden)\n","\n","        decoder_input = torch.Tensor([[SOS_token]]).long().to(device)\n","        decoder_hidden = encoder_hidden\n","        decoded_words = []\n","\n","        for di in range(target_max_length):\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            _, top_index = decoder_output.data.topk(1)\n","            if top_index.item() == EOS_token:\n","                decoded_words.append(\"<EOS>\")\n","                break\n","            else:\n","                decoded_words.append(target_vocab.index2vocab[top_index.item()])\n","\n","            decoder_input = top_index.squeeze().detach()\n","\n","        predict_words = decoded_words\n","        predict_sentence = \" \".join(predict_words)\n","        print(\"<\", predict_sentence)\n","        print(\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6bOwXZoSAIca"},"source":["# Declare max length for sentence\n","SOURCE_MAX_LENGTH = 10\n","TARGET_MAX_LENGTH = 12"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z4MnnXatca03"},"source":["import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7s3oSsr2AIcb"},"source":["# Preprocess the corpus\n","load_pairs, load_source_vocab, load_target_vocab = preprocess(raw, SOURCE_MAX_LENGTH, TARGET_MAX_LENGTH)\n","print(random.choice(load_pairs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ljuiyexwAIce"},"source":["# Declare the encoder and the decoder\n","enc_hidden_size = 16\n","dec_hidden_size = enc_hidden_size\n","enc = Encoder(load_source_vocab.n_vocab, enc_hidden_size).to(device)\n","dec = Decoder(dec_hidden_size, load_target_vocab.n_vocab).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kCbq5Ai9AIcg"},"source":["# Train seq2seq model\n","train(load_pairs, load_source_vocab, load_target_vocab, enc, dec, 5000, print_every=1000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpDC9YbxAIci"},"source":["# Check the model with given data\n","evaluate(load_pairs, load_source_vocab, load_target_vocab, enc, dec, TARGET_MAX_LENGTH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zX9PUGAiZ09t"},"source":[""],"execution_count":null,"outputs":[]}]}